TEST 11300
VAL 11300
TRAIN 33900
2022-06-22 13:56:20,708 Reading data from flair/corpus/kfold
2022-06-22 13:56:20,708 Train: flair/corpus/kfold/train.txt
2022-06-22 13:56:20,708 Dev: flair/corpus/kfold/valid.txt
2022-06-22 13:56:20,709 Test: flair/corpus/kfold/test.txt
2022-06-22 13:56:47,286 Computing label dictionary. Progress:
2022-06-22 13:56:48,961 Dictionary created for label 'length' with 5 values: long (seen 291669 times), short (seen 202696 times), space (seen 185291 times), elision (seen 10199 times)
2022-06-22 13:56:48,963 SequenceTagger predicts: Dictionary with 5 tags: <unk>, long, short, space, elision
2022-06-22 13:56:48,971 ----------------------------------------------------------------------------------------------------
2022-06-22 13:56:48,971 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=50, out_features=50, bias=True)
  (rnn): LSTM(50, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=7, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-06-22 13:56:48,971 ----------------------------------------------------------------------------------------------------
2022-06-22 13:56:48,971 Corpus: "Corpus: 33900 train + 11300 dev + 11300 test sentences"
2022-06-22 13:56:48,971 ----------------------------------------------------------------------------------------------------
2022-06-22 13:56:48,971 Parameters:
2022-06-22 13:56:48,972  - learning_rate: "0.100000"
2022-06-22 13:56:48,972  - mini_batch_size: "32"
2022-06-22 13:56:48,972  - patience: "3"
2022-06-22 13:56:48,972  - anneal_factor: "0.5"
2022-06-22 13:56:48,972  - max_epochs: "25"
2022-06-22 13:56:48,972  - shuffle: "True"
2022-06-22 13:56:48,972  - train_with_dev: "False"
2022-06-22 13:56:48,972  - batch_growth_annealing: "False"
2022-06-22 13:56:48,972 ----------------------------------------------------------------------------------------------------
2022-06-22 13:56:48,972 Model training base path: "flair/scansion_models/kfold"
2022-06-22 13:56:48,972 ----------------------------------------------------------------------------------------------------
2022-06-22 13:56:48,972 Device: cpu
2022-06-22 13:56:48,972 ----------------------------------------------------------------------------------------------------
2022-06-22 13:56:48,972 Embeddings storage mode: cpu
2022-06-22 13:56:48,972 ----------------------------------------------------------------------------------------------------
2022-06-22 13:57:29,741 epoch 1 - iter 106/1060 - loss 0.94177182 - samples/sec: 83.22 - lr: 0.100000
2022-06-22 13:58:09,864 epoch 1 - iter 212/1060 - loss 0.81540569 - samples/sec: 84.55 - lr: 0.100000
2022-06-22 13:58:51,301 epoch 1 - iter 318/1060 - loss 0.74811431 - samples/sec: 81.87 - lr: 0.100000
2022-06-22 13:59:36,314 epoch 1 - iter 424/1060 - loss 0.70472728 - samples/sec: 75.37 - lr: 0.100000
2022-06-22 14:00:18,487 epoch 1 - iter 530/1060 - loss 0.67375526 - samples/sec: 80.45 - lr: 0.100000
2022-06-22 14:01:01,244 epoch 1 - iter 636/1060 - loss 0.64870019 - samples/sec: 79.35 - lr: 0.100000
2022-06-22 14:01:44,523 epoch 1 - iter 742/1060 - loss 0.62767490 - samples/sec: 78.39 - lr: 0.100000
2022-06-22 14:02:27,135 epoch 1 - iter 848/1060 - loss 0.60908181 - samples/sec: 79.62 - lr: 0.100000
2022-06-22 14:03:10,744 epoch 1 - iter 954/1060 - loss 0.59293071 - samples/sec: 77.80 - lr: 0.100000
2022-06-22 14:03:52,748 epoch 1 - iter 1060/1060 - loss 0.57887404 - samples/sec: 80.77 - lr: 0.100000
2022-06-22 14:03:52,748 ----------------------------------------------------------------------------------------------------
2022-06-22 14:03:52,748 EPOCH 1 done: loss 0.5789 - lr 0.100000
2022-06-22 14:04:48,653 Evaluating as a multi-label problem: False
2022-06-22 14:04:50,034 DEV : loss 0.3825467526912689 - f1-score (micro avg)  0.8171
2022-06-22 14:04:50,623 BAD EPOCHS (no improvement): 0
2022-06-22 14:04:50,624 saving best model
2022-06-22 14:04:50,632 ----------------------------------------------------------------------------------------------------
2022-06-22 14:05:31,968 epoch 2 - iter 106/1060 - loss 0.43253036 - samples/sec: 82.08 - lr: 0.100000
2022-06-22 14:06:14,731 epoch 2 - iter 212/1060 - loss 0.42640240 - samples/sec: 79.34 - lr: 0.100000
2022-06-22 14:06:58,371 epoch 2 - iter 318/1060 - loss 0.42119945 - samples/sec: 77.75 - lr: 0.100000
2022-06-22 14:07:41,582 epoch 2 - iter 424/1060 - loss 0.41402105 - samples/sec: 78.52 - lr: 0.100000
2022-06-22 14:08:24,421 epoch 2 - iter 530/1060 - loss 0.40733750 - samples/sec: 79.20 - lr: 0.100000
2022-06-22 14:09:06,792 epoch 2 - iter 636/1060 - loss 0.40091421 - samples/sec: 80.07 - lr: 0.100000
2022-06-22 14:09:49,423 epoch 2 - iter 742/1060 - loss 0.39413684 - samples/sec: 79.58 - lr: 0.100000
2022-06-22 14:10:32,363 epoch 2 - iter 848/1060 - loss 0.38730934 - samples/sec: 79.01 - lr: 0.100000
2022-06-22 14:11:15,138 epoch 2 - iter 954/1060 - loss 0.38141500 - samples/sec: 79.32 - lr: 0.100000
2022-06-22 14:11:57,247 epoch 2 - iter 1060/1060 - loss 0.37572225 - samples/sec: 80.58 - lr: 0.100000
2022-06-22 14:11:57,247 ----------------------------------------------------------------------------------------------------
2022-06-22 14:11:57,247 EPOCH 2 done: loss 0.3757 - lr 0.100000
2022-06-22 14:12:52,346 Evaluating as a multi-label problem: False
2022-06-22 14:12:53,692 DEV : loss 0.24788835644721985 - f1-score (micro avg)  0.8853
2022-06-22 14:12:54,233 BAD EPOCHS (no improvement): 0
2022-06-22 14:12:54,234 saving best model
2022-06-22 14:12:54,244 ----------------------------------------------------------------------------------------------------
2022-06-22 14:13:35,507 epoch 3 - iter 106/1060 - loss 0.32216554 - samples/sec: 82.23 - lr: 0.100000
2022-06-22 14:14:16,971 epoch 3 - iter 212/1060 - loss 0.31805707 - samples/sec: 81.82 - lr: 0.100000
2022-06-22 14:14:58,353 epoch 3 - iter 318/1060 - loss 0.31311996 - samples/sec: 81.99 - lr: 0.100000
2022-06-22 14:15:40,148 epoch 3 - iter 424/1060 - loss 0.30886138 - samples/sec: 81.18 - lr: 0.100000
2022-06-22 14:16:23,271 epoch 3 - iter 530/1060 - loss 0.30525800 - samples/sec: 78.67 - lr: 0.100000
2022-06-22 14:17:04,857 epoch 3 - iter 636/1060 - loss 0.30197255 - samples/sec: 81.59 - lr: 0.100000
2022-06-22 14:17:45,517 epoch 3 - iter 742/1060 - loss 0.30036084 - samples/sec: 83.44 - lr: 0.100000
2022-06-22 14:18:25,926 epoch 3 - iter 848/1060 - loss 0.29729143 - samples/sec: 83.96 - lr: 0.100000
2022-06-22 14:19:06,159 epoch 3 - iter 954/1060 - loss 0.29505340 - samples/sec: 84.33 - lr: 0.100000
2022-06-22 14:19:45,850 epoch 3 - iter 1060/1060 - loss 0.29287861 - samples/sec: 85.48 - lr: 0.100000
2022-06-22 14:19:45,850 ----------------------------------------------------------------------------------------------------
2022-06-22 14:19:45,850 EPOCH 3 done: loss 0.2929 - lr 0.100000
2022-06-22 14:20:38,516 Evaluating as a multi-label problem: False
2022-06-22 14:20:39,812 DEV : loss 0.19740432500839233 - f1-score (micro avg)  0.9094
2022-06-22 14:20:40,339 BAD EPOCHS (no improvement): 0
2022-06-22 14:20:40,340 saving best model
2022-06-22 14:20:40,349 ----------------------------------------------------------------------------------------------------
2022-06-22 14:21:19,543 epoch 4 - iter 106/1060 - loss 0.25923686 - samples/sec: 86.57 - lr: 0.100000
2022-06-22 14:22:00,005 epoch 4 - iter 212/1060 - loss 0.26302867 - samples/sec: 83.85 - lr: 0.100000
2022-06-22 14:22:39,241 epoch 4 - iter 318/1060 - loss 0.26253700 - samples/sec: 86.47 - lr: 0.100000
2022-06-22 14:23:18,265 epoch 4 - iter 424/1060 - loss 0.26092747 - samples/sec: 86.94 - lr: 0.100000
2022-06-22 14:23:57,433 epoch 4 - iter 530/1060 - loss 0.25956919 - samples/sec: 86.62 - lr: 0.100000
2022-06-22 14:24:36,670 epoch 4 - iter 636/1060 - loss 0.25783042 - samples/sec: 86.47 - lr: 0.100000
2022-06-22 14:25:15,723 epoch 4 - iter 742/1060 - loss 0.25640905 - samples/sec: 86.88 - lr: 0.100000
2022-06-22 14:25:55,141 epoch 4 - iter 848/1060 - loss 0.25502365 - samples/sec: 86.07 - lr: 0.100000
2022-06-22 14:26:34,796 epoch 4 - iter 954/1060 - loss 0.25358312 - samples/sec: 85.56 - lr: 0.100000
2022-06-22 14:27:14,211 epoch 4 - iter 1060/1060 - loss 0.25242369 - samples/sec: 86.08 - lr: 0.100000
2022-06-22 14:27:14,211 ----------------------------------------------------------------------------------------------------
2022-06-22 14:27:14,211 EPOCH 4 done: loss 0.2524 - lr 0.100000
2022-06-22 14:28:07,261 Evaluating as a multi-label problem: False
2022-06-22 14:28:08,570 DEV : loss 0.165436789393425 - f1-score (micro avg)  0.9246
2022-06-22 14:28:09,108 BAD EPOCHS (no improvement): 0
2022-06-22 14:28:09,109 saving best model
2022-06-22 14:28:09,123 ----------------------------------------------------------------------------------------------------
2022-06-22 14:28:49,052 epoch 5 - iter 106/1060 - loss 0.22883231 - samples/sec: 84.97 - lr: 0.100000
2022-06-22 14:29:28,785 epoch 5 - iter 212/1060 - loss 0.23266241 - samples/sec: 85.39 - lr: 0.100000
2022-06-22 14:30:08,858 epoch 5 - iter 318/1060 - loss 0.23115024 - samples/sec: 84.66 - lr: 0.100000
2022-06-22 14:30:48,474 epoch 5 - iter 424/1060 - loss 0.23076369 - samples/sec: 85.64 - lr: 0.100000
2022-06-22 14:31:28,269 epoch 5 - iter 530/1060 - loss 0.22945211 - samples/sec: 85.25 - lr: 0.100000
2022-06-22 14:32:08,157 epoch 5 - iter 636/1060 - loss 0.22884108 - samples/sec: 85.06 - lr: 0.100000
2022-06-22 14:32:47,666 epoch 5 - iter 742/1060 - loss 0.22859526 - samples/sec: 85.87 - lr: 0.100000
2022-06-22 14:33:27,324 epoch 5 - iter 848/1060 - loss 0.22803312 - samples/sec: 85.55 - lr: 0.100000
2022-06-22 14:34:07,215 epoch 5 - iter 954/1060 - loss 0.22692580 - samples/sec: 85.05 - lr: 0.100000
2022-06-22 14:34:47,816 epoch 5 - iter 1060/1060 - loss 0.22595960 - samples/sec: 83.57 - lr: 0.100000
2022-06-22 14:34:47,817 ----------------------------------------------------------------------------------------------------
2022-06-22 14:34:47,817 EPOCH 5 done: loss 0.2260 - lr 0.100000
2022-06-22 14:35:40,569 Evaluating as a multi-label problem: False
2022-06-22 14:35:41,883 DEV : loss 0.14990204572677612 - f1-score (micro avg)  0.9325
2022-06-22 14:35:42,410 BAD EPOCHS (no improvement): 0
2022-06-22 14:35:42,411 saving best model
2022-06-22 14:35:42,420 ----------------------------------------------------------------------------------------------------
2022-06-22 14:36:22,515 epoch 6 - iter 106/1060 - loss 0.21298044 - samples/sec: 84.62 - lr: 0.100000
2022-06-22 14:37:01,933 epoch 6 - iter 212/1060 - loss 0.21075173 - samples/sec: 86.07 - lr: 0.100000
2022-06-22 14:37:42,179 epoch 6 - iter 318/1060 - loss 0.21114178 - samples/sec: 84.30 - lr: 0.100000
2022-06-22 14:38:22,624 epoch 6 - iter 424/1060 - loss 0.21145655 - samples/sec: 83.88 - lr: 0.100000
2022-06-22 14:39:02,464 epoch 6 - iter 530/1060 - loss 0.21046174 - samples/sec: 85.16 - lr: 0.100000
2022-06-22 14:39:43,091 epoch 6 - iter 636/1060 - loss 0.20948739 - samples/sec: 83.51 - lr: 0.100000
2022-06-22 14:40:23,015 epoch 6 - iter 742/1060 - loss 0.20929653 - samples/sec: 84.98 - lr: 0.100000
2022-06-22 14:41:02,890 epoch 6 - iter 848/1060 - loss 0.20908300 - samples/sec: 85.08 - lr: 0.100000
2022-06-22 14:41:43,204 epoch 6 - iter 954/1060 - loss 0.20883373 - samples/sec: 84.16 - lr: 0.100000
2022-06-22 14:42:22,506 epoch 6 - iter 1060/1060 - loss 0.20900263 - samples/sec: 86.33 - lr: 0.100000
2022-06-22 14:42:22,507 ----------------------------------------------------------------------------------------------------
2022-06-22 14:42:22,507 EPOCH 6 done: loss 0.2090 - lr 0.100000
2022-06-22 14:43:16,244 Evaluating as a multi-label problem: False
2022-06-22 14:43:17,564 DEV : loss 0.13861937820911407 - f1-score (micro avg)  0.9373
2022-06-22 14:43:18,095 BAD EPOCHS (no improvement): 0
2022-06-22 14:43:18,096 saving best model
2022-06-22 14:43:18,105 ----------------------------------------------------------------------------------------------------
2022-06-22 14:43:57,592 epoch 7 - iter 106/1060 - loss 0.20206827 - samples/sec: 85.93 - lr: 0.100000
2022-06-22 14:44:37,566 epoch 7 - iter 212/1060 - loss 0.20265987 - samples/sec: 84.87 - lr: 0.100000
2022-06-22 14:45:17,094 epoch 7 - iter 318/1060 - loss 0.20031316 - samples/sec: 85.83 - lr: 0.100000
2022-06-22 14:45:57,922 epoch 7 - iter 424/1060 - loss 0.20005726 - samples/sec: 83.10 - lr: 0.100000
2022-06-22 14:46:37,814 epoch 7 - iter 530/1060 - loss 0.19973119 - samples/sec: 85.05 - lr: 0.100000
2022-06-22 14:47:17,857 epoch 7 - iter 636/1060 - loss 0.19973386 - samples/sec: 84.73 - lr: 0.100000
2022-06-22 14:47:57,688 epoch 7 - iter 742/1060 - loss 0.19895974 - samples/sec: 85.18 - lr: 0.100000
2022-06-22 14:48:37,161 epoch 7 - iter 848/1060 - loss 0.19847063 - samples/sec: 85.95 - lr: 0.100000
2022-06-22 14:49:17,261 epoch 7 - iter 954/1060 - loss 0.19842497 - samples/sec: 84.61 - lr: 0.100000
2022-06-22 14:49:56,772 epoch 7 - iter 1060/1060 - loss 0.19763223 - samples/sec: 85.87 - lr: 0.100000
2022-06-22 14:49:56,772 ----------------------------------------------------------------------------------------------------
2022-06-22 14:49:56,772 EPOCH 7 done: loss 0.1976 - lr 0.100000
2022-06-22 14:50:50,144 Evaluating as a multi-label problem: False
2022-06-22 14:50:51,469 DEV : loss 0.13119883835315704 - f1-score (micro avg)  0.9419
2022-06-22 14:50:51,997 BAD EPOCHS (no improvement): 0
2022-06-22 14:50:52,080 saving best model
2022-06-22 14:50:52,089 ----------------------------------------------------------------------------------------------------
2022-06-22 14:51:32,397 epoch 8 - iter 106/1060 - loss 0.19263107 - samples/sec: 84.17 - lr: 0.100000
2022-06-22 14:52:12,449 epoch 8 - iter 212/1060 - loss 0.19256870 - samples/sec: 84.71 - lr: 0.100000
2022-06-22 14:52:51,597 epoch 8 - iter 318/1060 - loss 0.19119318 - samples/sec: 86.66 - lr: 0.100000
2022-06-22 14:53:31,697 epoch 8 - iter 424/1060 - loss 0.19044244 - samples/sec: 84.61 - lr: 0.100000
2022-06-22 14:54:11,305 epoch 8 - iter 530/1060 - loss 0.19017633 - samples/sec: 85.66 - lr: 0.100000
2022-06-22 14:54:50,758 epoch 8 - iter 636/1060 - loss 0.18929264 - samples/sec: 86.00 - lr: 0.100000
2022-06-22 14:55:30,376 epoch 8 - iter 742/1060 - loss 0.18944514 - samples/sec: 85.64 - lr: 0.100000
2022-06-22 14:56:09,460 epoch 8 - iter 848/1060 - loss 0.18917386 - samples/sec: 86.81 - lr: 0.100000
2022-06-22 14:56:48,310 epoch 8 - iter 954/1060 - loss 0.18789343 - samples/sec: 87.33 - lr: 0.100000
2022-06-22 14:57:32,084 epoch 8 - iter 1060/1060 - loss 0.18773612 - samples/sec: 77.51 - lr: 0.100000
2022-06-22 14:57:32,085 ----------------------------------------------------------------------------------------------------
2022-06-22 14:57:32,085 EPOCH 8 done: loss 0.1877 - lr 0.100000
2022-06-22 14:58:22,163 Evaluating as a multi-label problem: False
2022-06-22 14:58:23,474 DEV : loss 0.11921054124832153 - f1-score (micro avg)  0.9467
2022-06-22 14:58:24,001 BAD EPOCHS (no improvement): 0
2022-06-22 14:58:24,002 saving best model
2022-06-22 14:58:24,015 ----------------------------------------------------------------------------------------------------
2022-06-22 14:59:04,067 epoch 9 - iter 106/1060 - loss 0.17826037 - samples/sec: 84.71 - lr: 0.100000
2022-06-22 14:59:44,096 epoch 9 - iter 212/1060 - loss 0.17948957 - samples/sec: 84.76 - lr: 0.100000
2022-06-22 15:00:23,819 epoch 9 - iter 318/1060 - loss 0.18065245 - samples/sec: 85.41 - lr: 0.100000
2022-06-22 15:01:03,721 epoch 9 - iter 424/1060 - loss 0.18082551 - samples/sec: 85.03 - lr: 0.100000
2022-06-22 15:01:43,170 epoch 9 - iter 530/1060 - loss 0.18023195 - samples/sec: 86.01 - lr: 0.100000
2022-06-22 15:02:24,153 epoch 9 - iter 636/1060 - loss 0.17951424 - samples/sec: 82.78 - lr: 0.100000
2022-06-22 15:03:07,805 epoch 9 - iter 742/1060 - loss 0.18026904 - samples/sec: 77.72 - lr: 0.100000
2022-06-22 15:03:47,655 epoch 9 - iter 848/1060 - loss 0.18023243 - samples/sec: 85.14 - lr: 0.100000
2022-06-22 15:04:30,674 epoch 9 - iter 954/1060 - loss 0.17980285 - samples/sec: 78.87 - lr: 0.100000
2022-06-22 15:05:11,948 epoch 9 - iter 1060/1060 - loss 0.17931288 - samples/sec: 82.21 - lr: 0.100000
2022-06-22 15:05:11,948 ----------------------------------------------------------------------------------------------------
2022-06-22 15:05:11,948 EPOCH 9 done: loss 0.1793 - lr 0.100000
2022-06-22 15:06:04,030 Evaluating as a multi-label problem: False
2022-06-22 15:06:05,381 DEV : loss 0.11859223246574402 - f1-score (micro avg)  0.9471
2022-06-22 15:06:05,915 BAD EPOCHS (no improvement): 0
2022-06-22 15:06:05,917 saving best model
2022-06-22 15:06:05,925 ----------------------------------------------------------------------------------------------------
2022-06-22 15:06:46,753 epoch 10 - iter 106/1060 - loss 0.16986909 - samples/sec: 83.10 - lr: 0.100000
2022-06-22 15:07:30,975 epoch 10 - iter 212/1060 - loss 0.17092909 - samples/sec: 76.72 - lr: 0.100000
2022-06-22 15:08:13,547 epoch 10 - iter 318/1060 - loss 0.17365931 - samples/sec: 79.69 - lr: 0.100000
2022-06-22 15:08:55,758 epoch 10 - iter 424/1060 - loss 0.17402570 - samples/sec: 80.38 - lr: 0.100000
2022-06-22 15:09:42,732 epoch 10 - iter 530/1060 - loss 0.17427886 - samples/sec: 72.23 - lr: 0.100000
2022-06-22 15:10:24,987 epoch 10 - iter 636/1060 - loss 0.17292035 - samples/sec: 80.29 - lr: 0.100000
2022-06-22 15:11:06,005 epoch 10 - iter 742/1060 - loss 0.17233493 - samples/sec: 82.71 - lr: 0.100000
2022-06-22 15:11:46,835 epoch 10 - iter 848/1060 - loss 0.17209393 - samples/sec: 83.10 - lr: 0.100000
2022-06-22 15:12:29,146 epoch 10 - iter 954/1060 - loss 0.17261283 - samples/sec: 80.19 - lr: 0.100000
2022-06-22 15:13:11,733 epoch 10 - iter 1060/1060 - loss 0.17278370 - samples/sec: 79.67 - lr: 0.100000
2022-06-22 15:13:11,734 ----------------------------------------------------------------------------------------------------
2022-06-22 15:13:11,734 EPOCH 10 done: loss 0.1728 - lr 0.100000
2022-06-22 15:14:03,814 Evaluating as a multi-label problem: False
2022-06-22 15:14:05,264 DEV : loss 0.11123897135257721 - f1-score (micro avg)  0.9505
2022-06-22 15:14:05,815 BAD EPOCHS (no improvement): 0
2022-06-22 15:14:05,816 saving best model
2022-06-22 15:14:05,825 ----------------------------------------------------------------------------------------------------
2022-06-22 15:14:53,438 epoch 11 - iter 106/1060 - loss 0.17106837 - samples/sec: 71.26 - lr: 0.100000
2022-06-22 15:15:34,406 epoch 11 - iter 212/1060 - loss 0.16849676 - samples/sec: 82.81 - lr: 0.100000
2022-06-22 15:16:14,641 epoch 11 - iter 318/1060 - loss 0.16852206 - samples/sec: 84.32 - lr: 0.100000
2022-06-22 15:16:57,087 epoch 11 - iter 424/1060 - loss 0.16808848 - samples/sec: 79.93 - lr: 0.100000
2022-06-22 15:17:37,248 epoch 11 - iter 530/1060 - loss 0.16833078 - samples/sec: 84.48 - lr: 0.100000
2022-06-22 15:18:16,764 epoch 11 - iter 636/1060 - loss 0.16850489 - samples/sec: 85.86 - lr: 0.100000
2022-06-22 15:18:57,159 epoch 11 - iter 742/1060 - loss 0.16794236 - samples/sec: 83.99 - lr: 0.100000
2022-06-22 15:19:40,271 epoch 11 - iter 848/1060 - loss 0.16776222 - samples/sec: 78.70 - lr: 0.100000
2022-06-22 15:20:20,677 epoch 11 - iter 954/1060 - loss 0.16769628 - samples/sec: 83.97 - lr: 0.100000
2022-06-22 15:21:00,327 epoch 11 - iter 1060/1060 - loss 0.16750157 - samples/sec: 85.57 - lr: 0.100000
2022-06-22 15:21:00,327 ----------------------------------------------------------------------------------------------------
2022-06-22 15:21:00,327 EPOCH 11 done: loss 0.1675 - lr 0.100000
2022-06-22 15:21:54,179 Evaluating as a multi-label problem: False
2022-06-22 15:21:55,571 DEV : loss 0.10701093822717667 - f1-score (micro avg)  0.9527
2022-06-22 15:21:56,112 BAD EPOCHS (no improvement): 0
2022-06-22 15:21:56,113 saving best model
2022-06-22 15:21:56,121 ----------------------------------------------------------------------------------------------------
2022-06-22 15:22:37,774 epoch 12 - iter 106/1060 - loss 0.16638376 - samples/sec: 81.46 - lr: 0.100000
2022-06-22 15:23:21,493 epoch 12 - iter 212/1060 - loss 0.16553198 - samples/sec: 77.60 - lr: 0.100000
2022-06-22 15:24:03,837 epoch 12 - iter 318/1060 - loss 0.16473781 - samples/sec: 80.12 - lr: 0.100000
2022-06-22 15:24:45,388 epoch 12 - iter 424/1060 - loss 0.16395073 - samples/sec: 81.65 - lr: 0.100000
2022-06-22 15:25:26,580 epoch 12 - iter 530/1060 - loss 0.16432782 - samples/sec: 82.36 - lr: 0.100000
2022-06-22 15:26:08,898 epoch 12 - iter 636/1060 - loss 0.16390471 - samples/sec: 80.17 - lr: 0.100000
2022-06-22 15:26:51,240 epoch 12 - iter 742/1060 - loss 0.16406202 - samples/sec: 80.13 - lr: 0.100000
2022-06-22 15:27:33,811 epoch 12 - iter 848/1060 - loss 0.16415130 - samples/sec: 79.70 - lr: 0.100000
2022-06-22 15:28:16,233 epoch 12 - iter 954/1060 - loss 0.16336718 - samples/sec: 79.98 - lr: 0.100000
2022-06-22 15:28:58,544 epoch 12 - iter 1060/1060 - loss 0.16332830 - samples/sec: 80.19 - lr: 0.100000
2022-06-22 15:28:58,546 ----------------------------------------------------------------------------------------------------
2022-06-22 15:28:58,546 EPOCH 12 done: loss 0.1633 - lr 0.100000
2022-06-22 15:29:55,095 Evaluating as a multi-label problem: False
2022-06-22 15:29:56,435 DEV : loss 0.10443446040153503 - f1-score (micro avg)  0.9534
2022-06-22 15:29:56,970 BAD EPOCHS (no improvement): 0
2022-06-22 15:29:56,971 saving best model
2022-06-22 15:29:56,980 ----------------------------------------------------------------------------------------------------
2022-06-22 15:30:38,648 epoch 13 - iter 106/1060 - loss 0.15929767 - samples/sec: 81.43 - lr: 0.100000
2022-06-22 15:31:20,432 epoch 13 - iter 212/1060 - loss 0.15974264 - samples/sec: 81.20 - lr: 0.100000
2022-06-22 15:32:01,649 epoch 13 - iter 318/1060 - loss 0.16034268 - samples/sec: 82.32 - lr: 0.100000
2022-06-22 15:32:42,195 epoch 13 - iter 424/1060 - loss 0.16053131 - samples/sec: 83.68 - lr: 0.100000
2022-06-22 15:33:23,273 epoch 13 - iter 530/1060 - loss 0.16060322 - samples/sec: 82.59 - lr: 0.100000
2022-06-22 15:34:06,443 epoch 13 - iter 636/1060 - loss 0.15988063 - samples/sec: 78.59 - lr: 0.100000
2022-06-22 15:34:48,660 epoch 13 - iter 742/1060 - loss 0.15918171 - samples/sec: 80.37 - lr: 0.100000
2022-06-22 15:35:30,761 epoch 13 - iter 848/1060 - loss 0.15926367 - samples/sec: 80.58 - lr: 0.100000
2022-06-22 15:36:15,050 epoch 13 - iter 954/1060 - loss 0.15929359 - samples/sec: 76.61 - lr: 0.100000
2022-06-22 15:36:54,794 epoch 13 - iter 1060/1060 - loss 0.15873639 - samples/sec: 85.37 - lr: 0.100000
2022-06-22 15:36:54,795 ----------------------------------------------------------------------------------------------------
2022-06-22 15:36:54,795 EPOCH 13 done: loss 0.1587 - lr 0.100000
2022-06-22 15:37:51,465 Evaluating as a multi-label problem: False
2022-06-22 15:37:52,818 DEV : loss 0.10323414206504822 - f1-score (micro avg)  0.9548
2022-06-22 15:37:53,357 BAD EPOCHS (no improvement): 0
2022-06-22 15:37:53,359 saving best model
2022-06-22 15:37:53,367 ----------------------------------------------------------------------------------------------------
2022-06-22 15:38:36,363 epoch 14 - iter 106/1060 - loss 0.15377708 - samples/sec: 78.91 - lr: 0.100000
2022-06-22 15:39:17,434 epoch 14 - iter 212/1060 - loss 0.15478838 - samples/sec: 82.61 - lr: 0.100000
2022-06-22 15:39:59,320 epoch 14 - iter 318/1060 - loss 0.15451603 - samples/sec: 81.00 - lr: 0.100000
2022-06-22 15:40:42,976 epoch 14 - iter 424/1060 - loss 0.15531968 - samples/sec: 77.72 - lr: 0.100000
2022-06-22 15:41:25,576 epoch 14 - iter 530/1060 - loss 0.15524896 - samples/sec: 79.64 - lr: 0.100000
2022-06-22 15:42:06,919 epoch 14 - iter 636/1060 - loss 0.15438969 - samples/sec: 82.06 - lr: 0.100000
2022-06-22 15:42:48,793 epoch 14 - iter 742/1060 - loss 0.15420861 - samples/sec: 81.02 - lr: 0.100000
2022-06-22 15:43:31,296 epoch 14 - iter 848/1060 - loss 0.15445738 - samples/sec: 79.82 - lr: 0.100000
2022-06-22 15:44:11,250 epoch 14 - iter 954/1060 - loss 0.15458572 - samples/sec: 84.92 - lr: 0.100000
2022-06-22 15:44:51,309 epoch 14 - iter 1060/1060 - loss 0.15493769 - samples/sec: 84.70 - lr: 0.100000
2022-06-22 15:44:51,309 ----------------------------------------------------------------------------------------------------
2022-06-22 15:44:51,309 EPOCH 14 done: loss 0.1549 - lr 0.100000
2022-06-22 15:45:46,397 Evaluating as a multi-label problem: False
2022-06-22 15:45:47,714 DEV : loss 0.09903673082590103 - f1-score (micro avg)  0.9562
2022-06-22 15:45:48,254 BAD EPOCHS (no improvement): 0
2022-06-22 15:45:48,255 saving best model
2022-06-22 15:45:48,263 ----------------------------------------------------------------------------------------------------
2022-06-22 15:46:28,403 epoch 15 - iter 106/1060 - loss 0.15005541 - samples/sec: 84.53 - lr: 0.100000
2022-06-22 15:47:08,383 epoch 15 - iter 212/1060 - loss 0.15290463 - samples/sec: 84.86 - lr: 0.100000
2022-06-22 15:47:48,465 epoch 15 - iter 318/1060 - loss 0.15213695 - samples/sec: 84.64 - lr: 0.100000
2022-06-22 15:48:28,644 epoch 15 - iter 424/1060 - loss 0.15133482 - samples/sec: 84.44 - lr: 0.100000
2022-06-22 15:49:08,435 epoch 15 - iter 530/1060 - loss 0.15082007 - samples/sec: 85.27 - lr: 0.100000
2022-06-22 15:49:47,930 epoch 15 - iter 636/1060 - loss 0.15135869 - samples/sec: 85.90 - lr: 0.100000
2022-06-22 15:50:27,457 epoch 15 - iter 742/1060 - loss 0.15121967 - samples/sec: 85.83 - lr: 0.100000
2022-06-22 15:51:08,017 epoch 15 - iter 848/1060 - loss 0.15094831 - samples/sec: 83.65 - lr: 0.100000
2022-06-22 15:51:47,139 epoch 15 - iter 954/1060 - loss 0.15124181 - samples/sec: 86.72 - lr: 0.100000
2022-06-22 15:52:27,103 epoch 15 - iter 1060/1060 - loss 0.15146898 - samples/sec: 84.90 - lr: 0.100000
2022-06-22 15:52:27,103 ----------------------------------------------------------------------------------------------------
2022-06-22 15:52:27,103 EPOCH 15 done: loss 0.1515 - lr 0.100000
2022-06-22 15:53:17,351 Evaluating as a multi-label problem: False
2022-06-22 15:53:18,681 DEV : loss 0.096615269780159 - f1-score (micro avg)  0.9579
2022-06-22 15:53:19,218 BAD EPOCHS (no improvement): 0
2022-06-22 15:53:19,219 saving best model
2022-06-22 15:53:19,228 ----------------------------------------------------------------------------------------------------
2022-06-22 15:53:59,244 epoch 16 - iter 106/1060 - loss 0.14366405 - samples/sec: 84.79 - lr: 0.100000
2022-06-22 15:54:38,679 epoch 16 - iter 212/1060 - loss 0.14678580 - samples/sec: 86.03 - lr: 0.100000
2022-06-22 15:55:18,798 epoch 16 - iter 318/1060 - loss 0.14808586 - samples/sec: 84.57 - lr: 0.100000
2022-06-22 15:55:58,512 epoch 16 - iter 424/1060 - loss 0.14727753 - samples/sec: 85.43 - lr: 0.100000
2022-06-22 15:56:38,404 epoch 16 - iter 530/1060 - loss 0.14852223 - samples/sec: 85.05 - lr: 0.100000
2022-06-22 15:57:18,001 epoch 16 - iter 636/1060 - loss 0.14850373 - samples/sec: 85.68 - lr: 0.100000
2022-06-22 15:57:58,092 epoch 16 - iter 742/1060 - loss 0.14897014 - samples/sec: 84.62 - lr: 0.100000
2022-06-22 15:58:37,829 epoch 16 - iter 848/1060 - loss 0.14883220 - samples/sec: 85.38 - lr: 0.100000
2022-06-22 15:59:18,597 epoch 16 - iter 954/1060 - loss 0.14880702 - samples/sec: 83.22 - lr: 0.100000
2022-06-22 15:59:57,766 epoch 16 - iter 1060/1060 - loss 0.14836713 - samples/sec: 86.62 - lr: 0.100000
2022-06-22 15:59:57,767 ----------------------------------------------------------------------------------------------------
2022-06-22 15:59:57,767 EPOCH 16 done: loss 0.1484 - lr 0.100000
2022-06-22 16:00:51,826 Evaluating as a multi-label problem: False
2022-06-22 16:00:53,148 DEV : loss 0.09343791753053665 - f1-score (micro avg)  0.9593
2022-06-22 16:00:53,686 BAD EPOCHS (no improvement): 0
2022-06-22 16:00:53,687 saving best model
2022-06-22 16:00:53,695 ----------------------------------------------------------------------------------------------------
2022-06-22 16:01:33,549 epoch 17 - iter 106/1060 - loss 0.14766368 - samples/sec: 85.13 - lr: 0.100000
2022-06-22 16:02:14,120 epoch 17 - iter 212/1060 - loss 0.14766858 - samples/sec: 83.63 - lr: 0.100000
2022-06-22 16:02:53,917 epoch 17 - iter 318/1060 - loss 0.14715421 - samples/sec: 85.25 - lr: 0.100000
2022-06-22 16:03:33,025 epoch 17 - iter 424/1060 - loss 0.14622258 - samples/sec: 86.75 - lr: 0.100000
2022-06-22 16:04:13,155 epoch 17 - iter 530/1060 - loss 0.14646250 - samples/sec: 84.54 - lr: 0.100000
2022-06-22 16:04:52,562 epoch 17 - iter 636/1060 - loss 0.14653760 - samples/sec: 86.10 - lr: 0.100000
2022-06-22 16:05:36,041 epoch 17 - iter 742/1060 - loss 0.14609837 - samples/sec: 78.03 - lr: 0.100000
2022-06-22 16:06:15,556 epoch 17 - iter 848/1060 - loss 0.14560051 - samples/sec: 85.86 - lr: 0.100000
2022-06-22 16:06:55,528 epoch 17 - iter 954/1060 - loss 0.14576228 - samples/sec: 84.88 - lr: 0.100000
2022-06-22 16:07:34,600 epoch 17 - iter 1060/1060 - loss 0.14549960 - samples/sec: 86.84 - lr: 0.100000
2022-06-22 16:07:34,600 ----------------------------------------------------------------------------------------------------
2022-06-22 16:07:34,600 EPOCH 17 done: loss 0.1455 - lr 0.100000
2022-06-22 16:08:25,397 Evaluating as a multi-label problem: False
2022-06-22 16:08:26,728 DEV : loss 0.0918429046869278 - f1-score (micro avg)  0.9598
2022-06-22 16:08:27,270 BAD EPOCHS (no improvement): 0
2022-06-22 16:08:27,270 saving best model
2022-06-22 16:08:27,279 ----------------------------------------------------------------------------------------------------
2022-06-22 16:09:07,004 epoch 18 - iter 106/1060 - loss 0.14493360 - samples/sec: 85.41 - lr: 0.100000
2022-06-22 16:09:47,357 epoch 18 - iter 212/1060 - loss 0.14321847 - samples/sec: 84.08 - lr: 0.100000
2022-06-22 16:10:27,520 epoch 18 - iter 318/1060 - loss 0.14341394 - samples/sec: 84.48 - lr: 0.100000
2022-06-22 16:11:10,678 epoch 18 - iter 424/1060 - loss 0.14366317 - samples/sec: 78.61 - lr: 0.100000
2022-06-22 16:11:50,594 epoch 18 - iter 530/1060 - loss 0.14336335 - samples/sec: 85.00 - lr: 0.100000
2022-06-22 16:12:30,042 epoch 18 - iter 636/1060 - loss 0.14397383 - samples/sec: 86.01 - lr: 0.100000
2022-06-22 16:13:10,151 epoch 18 - iter 742/1060 - loss 0.14312115 - samples/sec: 84.59 - lr: 0.100000
2022-06-22 16:13:49,497 epoch 18 - iter 848/1060 - loss 0.14295069 - samples/sec: 86.23 - lr: 0.100000
2022-06-22 16:14:29,382 epoch 18 - iter 954/1060 - loss 0.14301961 - samples/sec: 85.06 - lr: 0.100000
2022-06-22 16:15:09,650 epoch 18 - iter 1060/1060 - loss 0.14310660 - samples/sec: 84.26 - lr: 0.100000
2022-06-22 16:15:09,651 ----------------------------------------------------------------------------------------------------
2022-06-22 16:15:09,651 EPOCH 18 done: loss 0.1431 - lr 0.100000
2022-06-22 16:16:00,490 Evaluating as a multi-label problem: False
2022-06-22 16:16:01,819 DEV : loss 0.08951305598020554 - f1-score (micro avg)  0.9604
2022-06-22 16:16:02,351 BAD EPOCHS (no improvement): 0
2022-06-22 16:16:02,352 saving best model
2022-06-22 16:16:02,361 ----------------------------------------------------------------------------------------------------
2022-06-22 16:16:42,012 epoch 19 - iter 106/1060 - loss 0.14154910 - samples/sec: 85.57 - lr: 0.100000
2022-06-22 16:17:25,653 epoch 19 - iter 212/1060 - loss 0.14044291 - samples/sec: 77.74 - lr: 0.100000
2022-06-22 16:18:05,444 epoch 19 - iter 318/1060 - loss 0.13888860 - samples/sec: 85.26 - lr: 0.100000
2022-06-22 16:18:45,120 epoch 19 - iter 424/1060 - loss 0.13941164 - samples/sec: 85.51 - lr: 0.100000
2022-06-22 16:19:24,681 epoch 19 - iter 530/1060 - loss 0.14024639 - samples/sec: 85.76 - lr: 0.100000
2022-06-22 16:20:04,376 epoch 19 - iter 636/1060 - loss 0.14074864 - samples/sec: 85.47 - lr: 0.100000
2022-06-22 16:20:44,219 epoch 19 - iter 742/1060 - loss 0.14079753 - samples/sec: 85.15 - lr: 0.100000
2022-06-22 16:21:24,975 epoch 19 - iter 848/1060 - loss 0.14066207 - samples/sec: 83.25 - lr: 0.100000
2022-06-22 16:22:04,938 epoch 19 - iter 954/1060 - loss 0.14049627 - samples/sec: 84.90 - lr: 0.100000
2022-06-22 16:22:44,545 epoch 19 - iter 1060/1060 - loss 0.14028297 - samples/sec: 85.66 - lr: 0.100000
2022-06-22 16:22:44,546 ----------------------------------------------------------------------------------------------------
2022-06-22 16:22:44,546 EPOCH 19 done: loss 0.1403 - lr 0.100000
2022-06-22 16:23:38,835 Evaluating as a multi-label problem: False
2022-06-22 16:23:40,153 DEV : loss 0.08885303884744644 - f1-score (micro avg)  0.9612
2022-06-22 16:23:40,692 BAD EPOCHS (no improvement): 0
2022-06-22 16:23:40,693 saving best model
2022-06-22 16:23:40,702 ----------------------------------------------------------------------------------------------------
2022-06-22 16:24:20,244 epoch 20 - iter 106/1060 - loss 0.13587209 - samples/sec: 85.80 - lr: 0.100000
2022-06-22 16:25:00,138 epoch 20 - iter 212/1060 - loss 0.13460333 - samples/sec: 85.04 - lr: 0.100000
2022-06-22 16:25:40,085 epoch 20 - iter 318/1060 - loss 0.13520205 - samples/sec: 84.93 - lr: 0.100000
2022-06-22 16:26:20,159 epoch 20 - iter 424/1060 - loss 0.13662105 - samples/sec: 84.66 - lr: 0.100000
2022-06-22 16:26:59,532 epoch 20 - iter 530/1060 - loss 0.13601620 - samples/sec: 86.17 - lr: 0.100000
2022-06-22 16:27:38,837 epoch 20 - iter 636/1060 - loss 0.13626130 - samples/sec: 86.32 - lr: 0.100000
2022-06-22 16:28:18,818 epoch 20 - iter 742/1060 - loss 0.13644863 - samples/sec: 84.86 - lr: 0.100000
2022-06-22 16:28:58,569 epoch 20 - iter 848/1060 - loss 0.13662861 - samples/sec: 85.35 - lr: 0.100000
2022-06-22 16:29:38,155 epoch 20 - iter 954/1060 - loss 0.13719976 - samples/sec: 85.71 - lr: 0.100000
2022-06-22 16:30:18,107 epoch 20 - iter 1060/1060 - loss 0.13720125 - samples/sec: 84.93 - lr: 0.100000
2022-06-22 16:30:18,107 ----------------------------------------------------------------------------------------------------
2022-06-22 16:30:18,107 EPOCH 20 done: loss 0.1372 - lr 0.100000
2022-06-22 16:31:08,709 Evaluating as a multi-label problem: False
2022-06-22 16:31:10,041 DEV : loss 0.08865189552307129 - f1-score (micro avg)  0.9609
2022-06-22 16:31:10,579 BAD EPOCHS (no improvement): 1
2022-06-22 16:31:10,579 ----------------------------------------------------------------------------------------------------
2022-06-22 16:31:50,453 epoch 21 - iter 106/1060 - loss 0.13940916 - samples/sec: 85.09 - lr: 0.100000
2022-06-22 16:32:29,958 epoch 21 - iter 212/1060 - loss 0.13707248 - samples/sec: 85.88 - lr: 0.100000
2022-06-22 16:33:13,902 epoch 21 - iter 318/1060 - loss 0.13685565 - samples/sec: 77.20 - lr: 0.100000
2022-06-22 16:33:53,784 epoch 21 - iter 424/1060 - loss 0.13717206 - samples/sec: 85.07 - lr: 0.100000
2022-06-22 16:34:33,106 epoch 21 - iter 530/1060 - loss 0.13650855 - samples/sec: 86.28 - lr: 0.100000
2022-06-22 16:35:13,359 epoch 21 - iter 636/1060 - loss 0.13570645 - samples/sec: 84.29 - lr: 0.100000
2022-06-22 16:35:53,231 epoch 21 - iter 742/1060 - loss 0.13602428 - samples/sec: 85.09 - lr: 0.100000
2022-06-22 16:36:33,293 epoch 21 - iter 848/1060 - loss 0.13619847 - samples/sec: 84.69 - lr: 0.100000
2022-06-22 16:37:13,860 epoch 21 - iter 954/1060 - loss 0.13603899 - samples/sec: 83.63 - lr: 0.100000
2022-06-22 16:37:53,122 epoch 21 - iter 1060/1060 - loss 0.13601353 - samples/sec: 86.42 - lr: 0.100000
2022-06-22 16:37:53,122 ----------------------------------------------------------------------------------------------------
2022-06-22 16:37:53,122 EPOCH 21 done: loss 0.1360 - lr 0.100000
2022-06-22 16:38:47,750 Evaluating as a multi-label problem: False
2022-06-22 16:38:49,078 DEV : loss 0.08624338358640671 - f1-score (micro avg)  0.963
2022-06-22 16:38:49,619 BAD EPOCHS (no improvement): 0
2022-06-22 16:38:49,621 saving best model
2022-06-22 16:38:49,634 ----------------------------------------------------------------------------------------------------
2022-06-22 16:39:29,567 epoch 22 - iter 106/1060 - loss 0.13041144 - samples/sec: 84.97 - lr: 0.100000
2022-06-22 16:40:09,483 epoch 22 - iter 212/1060 - loss 0.13056858 - samples/sec: 85.00 - lr: 0.100000
2022-06-22 16:40:49,159 epoch 22 - iter 318/1060 - loss 0.13214309 - samples/sec: 85.51 - lr: 0.100000
2022-06-22 16:41:29,086 epoch 22 - iter 424/1060 - loss 0.13276454 - samples/sec: 84.97 - lr: 0.100000
2022-06-22 16:42:09,045 epoch 22 - iter 530/1060 - loss 0.13327734 - samples/sec: 84.90 - lr: 0.100000
2022-06-22 16:42:48,613 epoch 22 - iter 636/1060 - loss 0.13331640 - samples/sec: 85.74 - lr: 0.100000
2022-06-22 16:43:28,158 epoch 22 - iter 742/1060 - loss 0.13367544 - samples/sec: 85.80 - lr: 0.100000
2022-06-22 16:44:08,126 epoch 22 - iter 848/1060 - loss 0.13356707 - samples/sec: 84.89 - lr: 0.100000
2022-06-22 16:44:48,304 epoch 22 - iter 954/1060 - loss 0.13372951 - samples/sec: 84.44 - lr: 0.100000
2022-06-22 16:45:27,889 epoch 22 - iter 1060/1060 - loss 0.13353321 - samples/sec: 85.71 - lr: 0.100000
2022-06-22 16:45:27,890 ----------------------------------------------------------------------------------------------------
2022-06-22 16:45:27,890 EPOCH 22 done: loss 0.1335 - lr 0.100000
2022-06-22 16:46:18,536 Evaluating as a multi-label problem: False
2022-06-22 16:46:19,879 DEV : loss 0.08626262098550797 - f1-score (micro avg)  0.9629
2022-06-22 16:46:20,411 BAD EPOCHS (no improvement): 1
2022-06-22 16:46:20,412 ----------------------------------------------------------------------------------------------------
2022-06-22 16:47:00,768 epoch 23 - iter 106/1060 - loss 0.13221804 - samples/sec: 84.08 - lr: 0.100000
2022-06-22 16:47:44,110 epoch 23 - iter 212/1060 - loss 0.13088757 - samples/sec: 78.28 - lr: 0.100000
2022-06-22 16:48:24,525 epoch 23 - iter 318/1060 - loss 0.13205591 - samples/sec: 83.95 - lr: 0.100000
2022-06-22 16:49:04,255 epoch 23 - iter 424/1060 - loss 0.13017355 - samples/sec: 85.39 - lr: 0.100000
2022-06-22 16:49:44,139 epoch 23 - iter 530/1060 - loss 0.12950552 - samples/sec: 85.07 - lr: 0.100000
2022-06-22 16:50:23,859 epoch 23 - iter 636/1060 - loss 0.13057850 - samples/sec: 85.42 - lr: 0.100000
2022-06-22 16:51:03,665 epoch 23 - iter 742/1060 - loss 0.13075896 - samples/sec: 85.23 - lr: 0.100000
2022-06-22 16:51:43,523 epoch 23 - iter 848/1060 - loss 0.13120612 - samples/sec: 85.12 - lr: 0.100000
2022-06-22 16:52:23,173 epoch 23 - iter 954/1060 - loss 0.13169863 - samples/sec: 85.57 - lr: 0.100000
2022-06-22 16:53:02,611 epoch 23 - iter 1060/1060 - loss 0.13163031 - samples/sec: 86.03 - lr: 0.100000
2022-06-22 16:53:02,611 ----------------------------------------------------------------------------------------------------
2022-06-22 16:53:02,611 EPOCH 23 done: loss 0.1316 - lr 0.100000
2022-06-22 16:53:56,558 Evaluating as a multi-label problem: False
2022-06-22 16:53:57,882 DEV : loss 0.08252190053462982 - f1-score (micro avg)  0.9643
2022-06-22 16:53:58,417 BAD EPOCHS (no improvement): 0
2022-06-22 16:53:58,418 saving best model
2022-06-22 16:53:58,426 ----------------------------------------------------------------------------------------------------
2022-06-22 16:54:38,207 epoch 24 - iter 106/1060 - loss 0.12445232 - samples/sec: 85.29 - lr: 0.100000
2022-06-22 16:55:17,331 epoch 24 - iter 212/1060 - loss 0.12571182 - samples/sec: 86.72 - lr: 0.100000
2022-06-22 16:55:57,088 epoch 24 - iter 318/1060 - loss 0.12667519 - samples/sec: 85.34 - lr: 0.100000
2022-06-22 16:56:37,112 epoch 24 - iter 424/1060 - loss 0.12773215 - samples/sec: 84.77 - lr: 0.100000
2022-06-22 16:57:17,491 epoch 24 - iter 530/1060 - loss 0.12865797 - samples/sec: 84.02 - lr: 0.100000
2022-06-22 16:57:58,488 epoch 24 - iter 636/1060 - loss 0.12831159 - samples/sec: 82.75 - lr: 0.100000
2022-06-22 16:58:38,514 epoch 24 - iter 742/1060 - loss 0.12963067 - samples/sec: 84.76 - lr: 0.100000
2022-06-22 16:59:18,548 epoch 24 - iter 848/1060 - loss 0.12994918 - samples/sec: 84.75 - lr: 0.100000
2022-06-22 16:59:58,532 epoch 24 - iter 954/1060 - loss 0.12984011 - samples/sec: 84.85 - lr: 0.100000
2022-06-22 17:00:37,614 epoch 24 - iter 1060/1060 - loss 0.12967571 - samples/sec: 86.82 - lr: 0.100000
2022-06-22 17:00:37,614 ----------------------------------------------------------------------------------------------------
2022-06-22 17:00:37,614 EPOCH 24 done: loss 0.1297 - lr 0.100000
2022-06-22 17:01:32,820 Evaluating as a multi-label problem: False
2022-06-22 17:01:34,147 DEV : loss 0.08468441665172577 - f1-score (micro avg)  0.9631
2022-06-22 17:01:34,681 BAD EPOCHS (no improvement): 1
2022-06-22 17:01:34,683 ----------------------------------------------------------------------------------------------------
2022-06-22 17:02:14,492 epoch 25 - iter 106/1060 - loss 0.12692916 - samples/sec: 85.23 - lr: 0.100000
2022-06-22 17:02:54,631 epoch 25 - iter 212/1060 - loss 0.12814890 - samples/sec: 84.52 - lr: 0.100000
2022-06-22 17:03:34,441 epoch 25 - iter 318/1060 - loss 0.12648298 - samples/sec: 85.22 - lr: 0.100000
2022-06-22 17:04:14,377 epoch 25 - iter 424/1060 - loss 0.12669167 - samples/sec: 84.95 - lr: 0.100000
2022-06-22 17:04:53,903 epoch 25 - iter 530/1060 - loss 0.12737386 - samples/sec: 85.84 - lr: 0.100000
2022-06-22 17:05:33,582 epoch 25 - iter 636/1060 - loss 0.12799398 - samples/sec: 85.50 - lr: 0.100000
2022-06-22 17:06:13,697 epoch 25 - iter 742/1060 - loss 0.12844026 - samples/sec: 84.58 - lr: 0.100000
2022-06-22 17:06:53,694 epoch 25 - iter 848/1060 - loss 0.12871271 - samples/sec: 84.83 - lr: 0.100000
2022-06-22 17:07:33,577 epoch 25 - iter 954/1060 - loss 0.12896572 - samples/sec: 85.07 - lr: 0.100000
2022-06-22 17:08:13,319 epoch 25 - iter 1060/1060 - loss 0.12885319 - samples/sec: 85.37 - lr: 0.100000
2022-06-22 17:08:13,320 ----------------------------------------------------------------------------------------------------
2022-06-22 17:08:13,320 EPOCH 25 done: loss 0.1289 - lr 0.100000
2022-06-22 17:09:06,826 Evaluating as a multi-label problem: False
2022-06-22 17:09:08,156 DEV : loss 0.08216261863708496 - f1-score (micro avg)  0.964
2022-06-22 17:09:08,688 BAD EPOCHS (no improvement): 2
2022-06-22 17:09:08,698 ----------------------------------------------------------------------------------------------------
2022-06-22 17:09:08,699 loading file flair/scansion_models/kfold/best-model.pt
2022-06-22 17:09:08,703 SequenceTagger predicts: Dictionary with 7 tags: <unk>, long, short, space, elision, <START>, <STOP>
2022-06-22 17:09:57,601 Evaluating as a multi-label problem: False
2022-06-22 17:09:58,919 0.9638	0.9638	0.9638	0.9638
2022-06-22 17:09:58,919 
Results:
- F-score (micro) 0.9638
- F-score (macro) 0.9479
- Accuracy 0.9638

By class:
              precision    recall  f1-score   support

        long     0.9685    0.9728    0.9706     97220
       short     0.9597    0.9517    0.9557     67414
       space     0.9638    0.9672    0.9655     61667
     elision     0.9124    0.8877    0.8999      3427

    accuracy                         0.9638    229728
   macro avg     0.9511    0.9448    0.9479    229728
weighted avg     0.9638    0.9638    0.9638    229728

2022-06-22 17:09:58,919 ----------------------------------------------------------------------------------------------------
TEST 11300
VAL 11300
TRAIN 33900
2022-06-22 17:09:59,390 Reading data from flair/corpus/kfold
2022-06-22 17:09:59,390 Train: flair/corpus/kfold/train.txt
2022-06-22 17:09:59,390 Dev: flair/corpus/kfold/valid.txt
2022-06-22 17:09:59,390 Test: flair/corpus/kfold/test.txt
2022-06-22 17:10:31,936 Computing label dictionary. Progress:
2022-06-22 17:10:33,653 Dictionary created for label 'length' with 5 values: long (seen 291634 times), short (seen 202442 times), space (seen 185053 times), elision (seen 10218 times)
2022-06-22 17:10:33,654 SequenceTagger predicts: Dictionary with 5 tags: <unk>, long, short, space, elision
2022-06-22 17:10:33,667 ----------------------------------------------------------------------------------------------------
2022-06-22 17:10:33,667 Model: "SequenceTagger(
  (embeddings): StackedEmbeddings(
    (list_embedding_0): CharacterEmbeddings(
      (char_embedding): Embedding(275, 25)
      (char_rnn): LSTM(25, 25, bidirectional=True)
    )
  )
  (word_dropout): WordDropout(p=0.05)
  (locked_dropout): LockedDropout(p=0.5)
  (embedding2nn): Linear(in_features=50, out_features=50, bias=True)
  (rnn): LSTM(50, 256, batch_first=True, bidirectional=True)
  (linear): Linear(in_features=512, out_features=7, bias=True)
  (loss_function): ViterbiLoss()
  (crf): CRF()
)"
2022-06-22 17:10:33,667 ----------------------------------------------------------------------------------------------------
2022-06-22 17:10:33,667 Corpus: "Corpus: 33900 train + 11300 dev + 11300 test sentences"
2022-06-22 17:10:33,667 ----------------------------------------------------------------------------------------------------
2022-06-22 17:10:33,668 Parameters:
2022-06-22 17:10:33,668  - learning_rate: "0.100000"
2022-06-22 17:10:33,668  - mini_batch_size: "32"
2022-06-22 17:10:33,668  - patience: "3"
2022-06-22 17:10:33,668  - anneal_factor: "0.5"
2022-06-22 17:10:33,668  - max_epochs: "25"
2022-06-22 17:10:33,668  - shuffle: "True"
2022-06-22 17:10:33,668  - train_with_dev: "False"
2022-06-22 17:10:33,668  - batch_growth_annealing: "False"
2022-06-22 17:10:33,668 ----------------------------------------------------------------------------------------------------
2022-06-22 17:10:33,668 Model training base path: "flair/scansion_models/kfold"
2022-06-22 17:10:33,668 ----------------------------------------------------------------------------------------------------
2022-06-22 17:10:33,669 Device: cpu
2022-06-22 17:10:33,669 ----------------------------------------------------------------------------------------------------
2022-06-22 17:10:33,669 Embeddings storage mode: cpu
2022-06-22 17:10:33,669 ----------------------------------------------------------------------------------------------------
